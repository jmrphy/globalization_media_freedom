who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df1<-as.data.frame(retweeter_poster)
el.df1<-el.df1[order(el.df1$who_post),]
el.df1<-el.df1[-grep(" ", el.df1$who_post),]  # remove RTs of multiples
rownames(el.df1)<-NULL
write.csv(el.df1, "cleaned_data/migration_el1.csv")
##### Network Snapshot 2
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per2$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per2[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df2<-as.data.frame(retweeter_poster)
el.df2<-el.df2[order(el.df2$who_post),]
el.df2<-el.df2[-grep(" ", el.df2$who_post),]  # remove RTs of multiples
rownames(el.df2)<-NULL
write.csv(el.df2, "cleaned_data/migration_el2.csv")
##### Network Snapshot 3
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per3$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per3[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df3<-as.data.frame(retweeter_poster)
el.df3<-el.df3[order(el.df3$who_post),]
el.df3<-el.df3[-grep(" ", el.df3$who_post),]  # remove RTs of multiples
rownames(el.df3)<-NULL
write.csv(el.df3, "cleaned_data/migration_el3.csv")
##### Network Snapshot 4
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per4$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per4[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df4<-as.data.frame(retweeter_poster)
el.df4<-el.df4[order(el.df4$who_post),]
el.df4<-el.df4[-grep(" ", el.df4$who_post),]  # remove RTs of multiples
rownames(el.df4)<-NULL
write.csv(el.df4, "cleaned_data/migration_el4.csv")
##### Network Snapshot 5
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per5$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per5[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df5<-as.data.frame(retweeter_poster)
el.df5<-el.df5[order(el.df5$who_post),]
el.df5<-el.df5[-grep(" ", el.df5$who_post),]  # remove RTs of multiples
rownames(el.df5)<-NULL
write.csv(el.df5, "cleaned_data/migration_el5.csv")
setwd("~/Dropbox/gh_projects/migration_tweets/cleaned_data")
el.df1<-read.csv("migration_el1.csv") # read in edgelist
el.df2<-read.csv("migration_el2.csv") # read in edgelist
el.df3<-read.csv("migration_el3.csv") # read in edgelist
el.df4<-read.csv("migration_el4.csv") # read in edgelist
el.df5<-read.csv("migration_el5.csv") # read in edgelist
setwd("~/Dropbox/gh_projects/migration_tweets")
el.df1<-el.df1[,2:3]
el.df2<-el.df2[,2:3]
el.df3<-el.df3[,2:3]
el.df4<-el.df4[,2:3]
el.df5<-el.df5[,2:3]
rt_graph2.1 = graph.edgelist(as.matrix(el.df1), directed=TRUE)
rt_graph2.2 = graph.edgelist(as.matrix(el.df2), directed=TRUE)
rt_graph2.3 = graph.edgelist(as.matrix(el.df3), directed=TRUE)
rt_graph2.4 = graph.edgelist(as.matrix(el.df4), directed=TRUE)
rt_graph2.5 = graph.edgelist(as.matrix(el.df5), directed=TRUE)
# Make and plot graph
rt_graph2.1 = delete.vertices(rt_graph2.1, V(rt_graph2.1)[ degree(rt_graph2.1)<=1 ])
rt_graph2.2 = delete.vertices(rt_graph2.2, V(rt_graph2.2)[ degree(rt_graph2.2)<=1 ])
rt_graph2.3 = delete.vertices(rt_graph2.3, V(rt_graph2.3)[ degree(rt_graph2.3)<=1 ])
rt_graph2.4 = delete.vertices(rt_graph2.4, V(rt_graph2.4)[ degree(rt_graph2.4)<=1 ])
rt_graph2.5 = delete.vertices(rt_graph2.5, V(rt_graph2.5)[ degree(rt_graph2.5)<=1 ])
V(rt_graph2.1)$color[betweenness(rt_graph2.1)>1000] =  rgb(1,0,0,1)
V(rt_graph2.2)$color[betweenness(rt_graph2.2)>1000] =  rgb(1,0,0,1)
V(rt_graph2.3)$color[betweenness(rt_graph2.3)>1000] =  rgb(1,0,0,1)
V(rt_graph2.4)$color[betweenness(rt_graph2.4)>1000] =  rgb(1,0,0,1)
V(rt_graph2.5)$color[betweenness(rt_graph2.5)>1000] =  rgb(1,0,0,1)
V(rt_graph2.1)$color[evcent(rt_graph2.1)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.2)$color[evcent(rt_graph2.2)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.3)$color[evcent(rt_graph2.3)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.4)$color[evcent(rt_graph2.4)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.5)$color[evcent(rt_graph2.5)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.1)$size = 2
V(rt_graph2.2)$size = 2
V(rt_graph2.3)$size = 2
V(rt_graph2.4)$size = 2
V(rt_graph2.5)$size = 2
V(rt_graph2.1)$label[evcent(rt_graph2.1)$vector>.3] = V(rt_graph2.1)$name[evcent(rt_graph2.1)$vector>.3]
V(rt_graph2.2)$label[evcent(rt_graph2.2)$vector>.3] = V(rt_graph2.2)$name[evcent(rt_graph2.2)$vector>.3]
V(rt_graph2.3)$label[evcent(rt_graph2.3)$vector>.3] = V(rt_graph2.3)$name[evcent(rt_graph2.3)$vector>.3]
V(rt_graph2.4)$label[evcent(rt_graph2.4)$vector>.3] = V(rt_graph2.4)$name[evcent(rt_graph2.4)$vector>.3]
V(rt_graph2.5)$label[evcent(rt_graph2.5)$vector>.3] = V(rt_graph2.5)$name[evcent(rt_graph2.5)$vector>.3]
V(rt_graph2.1)$label[betweenness(rt_graph2.1)>1000] = V(rt_graph2.1)$name[betweenness(rt_graph2.1)>1000]
V(rt_graph2.2)$label[betweenness(rt_graph2.2)>1000] = V(rt_graph2.2)$name[betweenness(rt_graph2.2)>1000]
V(rt_graph2.3)$label[betweenness(rt_graph2.3)>1000] = V(rt_graph2.3)$name[betweenness(rt_graph2.3)>1000]
V(rt_graph2.4)$label[betweenness(rt_graph2.4)>1000] = V(rt_graph2.4)$name[betweenness(rt_graph2.4)>1000]
V(rt_graph2.5)$label[betweenness(rt_graph2.5)>1000] = V(rt_graph2.5)$name[betweenness(rt_graph2.5)>1000]
V(rt_graph2.1)$label.cex = 1.2
V(rt_graph2.2)$label.cex = 1.2
V(rt_graph2.3)$label.cex = 1.2
V(rt_graph2.4)$label.cex = 1.2
V(rt_graph2.5)$label.cex = 1.2
E(rt_graph2.1)$width = .3
E(rt_graph2.2)$width = .3
E(rt_graph2.3)$width = .3
E(rt_graph2.4)$width = .3
E(rt_graph2.5)$width = .3
E(rt_graph2.1)$color = rgb(.5,.5,0,.1)
E(rt_graph2.2)$color = rgb(.5,.5,0,.1)
E(rt_graph2.3)$color = rgb(.5,.5,0,.1)
E(rt_graph2.4)$color = rgb(.5,.5,0,.1)
E(rt_graph2.5)$color = rgb(.5,.5,0,.1)
set.seed(4074)
par(bg="white", mar=c(1,1,1,1), mfrow=c(2,3))
plot.igraph(rt_graph2.1, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 1")
plot.igraph(rt_graph2.2, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 2")
plot.igraph(rt_graph2.3, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 3")
plot.igraph(rt_graph2.4, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 4")
plot.igraph(rt_graph2.5, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 5")
set.seed(4074)
par(bg="white", mar=c(1,1,1,1), mfrow=c(2,3))
plot.igraph(rt_graph2.1, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 1")
plot.igraph(rt_graph2.2, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 2")
plot.igraph(rt_graph2.3, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 3")
plot.igraph(rt_graph2.4, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 4")
plot.igraph(rt_graph2.5, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 5")
df$cleantext<-gsub('http.* *', ' ', df$text)
df$cleantext<-str_replace_all(df$cleantext, "[^[:alnum:]]", " ")
corp<-Corpus(VectorSource(df$cleantext))
corp <- tm_map(corp, removeNumbers)
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, stripWhitespace)
my_stopwords <- c(stopwords('english'), paste(unique(df$screenName)))
corp <- tm_map(corp, removeWords, my_stopwords)
corp <- tm_map(corp, tolower)
corp.full<-corp
corp <- tm_map(corp, stemDocument, language = "english") #reduce all English words to their roots
# other_stop_words<-c("psa", "polit", "rt", "panel", "amp", "politicalspik", "angeliawilson",
#                     "politicsir", "peterjohn", "the")
# corp <- tm_map(corp, removeWords, other_stop_words)   # remove specific word (the hashtag of interest)
dtm <-DocumentTermMatrix(corp) # make a matrix of each document by every single term
dtm <- removeSparseTerms(dtm, 0.99)
terms<-as.data.frame(sort(colSums(inspect(dtm)), decreasing=TRUE))
terms$Term <- rownames(terms)
names(terms)<-c("Frequency", "Term")
rownames(terms) = NULL
terms[1:50,1:2]
?inspect
terms<-as.data.frame(sort(colSums(dtm), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(summary(dtm)), decreasing=TRUE))
dtm
terms<-as.data.frame(sort(colSums(table(dtm)), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(dtm), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(inspect(dtm)), decreasing=TRUE))
terms$Term <- rownames(terms)
names(terms)<-c("Frequency", "Term")
rownames(terms) = NULL
terms[1:50,1:2]
setwd("~/Dropbox/gh_projects/migration_tweets/preliminary")
hu.liu.pos=scan("positive-words.txt",what='character',comment.char=';') #load +ve sentiment word list
hu.liu.neg=scan("negative-words.txt",what='character',comment.char=';') #load -ve sentiment word list
pos.words=c(hu.liu.pos)
neg.words=c(hu.liu.neg)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array ("a") of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
corp.full<-unlist(corp.full)
corp.scores<-score.sentiment(corp.full,pos.words,neg.words,.progress='text') # get scores for the tweet text
ggplot(corp.scores, aes(x=score)) + geom_histogram(binwidth=1) + xlab("Sentiment score") + ylab("Frequency") + theme_bw() + ggtitle("The Distribution of Sentiment")
corp.pos<-subset(corp.scores,corp.scores$score>=4) # get tweets with only very +ve scores
corp.neg<-subset(corp.scores,corp.scores$score<=-4) # get tweets with only very -ve scores
mean(corp.scores$score)
corp.pos[1:30,]
corp.neg[1:30,]
View(corp.pos)
corp.pos$text[1:30,]
View(corp.pos)
corp.pos$text[1:30,]
corp.pos$text[1:30]
c = rep(0:1,each=500)
c
x = rnorm(1000)
?rnorm
hist(x)
?rnorm
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
?runif
runif(1000)
log.int = glm(y~as.factor(c)*x, family=binomial)
y = (runif(1000) < link_lp)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
mycols = c("red","blue")
plot(log.int$fitted.values ~ x, col=mycols)
c = rep(0:1,each=500)
x = rnorm(1000)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
y = (runif(1000) < link_lp)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
mycols = c("red","blue")
plot(log.int$fitted.values ~ x, col=mycols)
install.packages("interplot")
devtools::install_github("sammo3182/interplot")
c = rep(0:1,each=5)
x = rnorm(10)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
y = (runif(10) < link_lp)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
c = rep(0:1,each=50)
x = rnorm(100)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
y = (runif(100) < link_lp)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
mycols = c("red","blue")
plot(log.int$fitted.values ~ x, col=mycols)
df<-data.frame()
df$c = rep(0:1,each=50)
df$x = rnorm(100)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(100) < link_lp)
df<-data.frame(matrix(100))
df<-data.frame(matrix(100,100))
df<-data.frame(matrix[2,100])
matrix[2,100]
?matrix
df<-data.frame(matrix(nrow=100,ncol=2))
df$c = rep(0:1,each=50)
df$x = rnorm(100)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(100) < link_lp)
View(df)
df<-data.frame(matrix(nrow=100,ncol=0))
df$c = rep(0:1,each=50)
df$x = rnorm(100)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(100) < link_lp)
View(df)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
View(df)
df<-data.frame(matrix(nrow=30,ncol=0))
df$c = rep(0:1,each=15)
df$x = rnorm(30)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(30) < link_lp)
df<-data.frame(matrix(nrow=30,ncol=0))
df$c = rep(0:1,each=15)
df$x = rnorm(30)
lp = -3 + 2*c*x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(30) < link_lp)
df<-data.frame(matrix(nrow=30,ncol=0))
df$c = rep(0:1,each=15)
df$x = rnorm(30)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(30) < link_lp)
log.int = glm(y~as.factor(c)*x, family=binomial)
summary(log.int)
mycols = c("red","blue")
plot(log.int$fitted.values ~ x, col=mycols)
install.packages("interplot")
require(visreg)
?visreg
visreg(log.int)
df<-data.frame(matrix(nrow=30,ncol=0))
df$c = rep(0:1,each=15)
df$x = rnorm(30)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(30) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
df<-data.frame(matrix(nrow=50,ncol=0))
df$c = rep(0:1,each=25)
df$x = rnorm(50)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(50) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
df<-data.frame(matrix(nrow=100,ncol=0))
df$c = rep(0:1,each=50)
df$x = rnorm(100)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(100) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
visreg(log.int, xvar="x", by="c")
?visreg
visreg(log.int, xvar="x", by="c", scale="response")
?visreg
visreg(log.int, xvar="x", by="c", scale="response", type="conditional")
visreg(log.int, xvar="x", by="c", scale="response", type="contrast")
visreg(log.int, xvar="x", by="c", scale="response", type="contrast")
visreg(log.int, xvar="x", by="c", scale="response", type="conditional")
?visreg
visreg(log.int, xvar="x", by="c", scale="response", partial="false")
visreg(log.int, xvar="x", by="c", scale="response", partial=F)
?visreg
visreg(log.int, xvar="x", by="c", scale="response", overlay=T)
df<-data.frame(matrix(nrow=500,ncol=0))
df$c = rep(0:1,each=250)
df$x = rnorm(500)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(500) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
visreg(log.int, xvar="x", by="c", scale="response", overlay=T)
df<-data.frame(matrix(nrow=500,ncol=0))
df$c = rep(0:1,each=250)
df$x = rnorm(500)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(500) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
mycols = c("red","blue")
plot(log.int$fitted.values ~ x, col=mycols)
visreg(log.int, xvar="x", by="c", scale="response", overlay=T)
df<-data.frame(matrix(nrow=1000,ncol=0))
df$c = rep(0:1,each=500)
df$x = rnorm(1000)
lp = -3 + 2*df$c*df$x
link_lp = exp(lp)/(1 + exp(lp))
df$y = (runif(1000) < link_lp)
log.int = glm(y~as.factor(c)*x, data=df, family=binomial)
summary(log.int)
visreg(log.int, xvar="x", by="c", scale="response", overlay=T)
visreg(log.int, xvar="x", by="c", scale="response", overlay=T, rug=0)
require(psych)
set.seed(42)
data.df <- sim.anova(es1=1,es2=.5,es13=1)  # one main effect and one interaction
describe(data.df)
pairs.panels(data.df)   #show how the design variables are orthogonal
### Define the URL where the dataset (.csv) is located
url<-"http://dl.dropboxusercontent.com/u/20498362/uk_social_attitudes_survey_2011/uk_social_attitudes_survey_2011.csv"
### Read in the data from the url we just defined, call it "data"
data <- read.csv(url)
url<-"http://dl.dropboxusercontent.com/u/20498362/uk_social_attitudes_survey_2011/uk_social_attitudes_survey_2011.csv"
data <- read.csv(url)
url<-"https://dl.dropboxusercontent.com/u/20498362/uk_social_attitudes_survey_2011/uk_social_attitudes_survey_2011.csv"
data <- read.csv(url)
summary(data$censor)
summary(data$Censor)
devtools::install_github("jmrphy/rtemplates")
devtools::install_github("jmrphy/rtemplates")
devtools::install_github("jmrphy/rtemplates")
devtools::install_github("jmrphy/rtemplates")
setwd("~/Dropbox/gh_projects/globalization_media_freedom")
packrat::init()
require(packrat)
?init
library("mgcv", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
detach("package:mgcv", unload=TRUE)
packrat::init(options = list(external.packages = c("mgcv")))
install.packages("quantreg")
packrat::init(options = list(external.packages = c("mgcv")))
